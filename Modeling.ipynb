{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f017ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52ac2b",
   "metadata": {},
   "source": [
    "Put this data into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e75fc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>2015</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>Developing</td>\n",
       "      <td>Developing</td>\n",
       "      <td>Developing</td>\n",
       "      <td>Developing</td>\n",
       "      <td>Developing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Life_Expectancy</th>\n",
       "      <td>65.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>59.9</td>\n",
       "      <td>59.5</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult Mortality</th>\n",
       "      <td>263.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infant deaths</th>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage_Expenditure</th>\n",
       "      <td>71.279624</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>7.097109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hepatitis B</th>\n",
       "      <td>65.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measles</th>\n",
       "      <td>1154</td>\n",
       "      <td>492</td>\n",
       "      <td>430</td>\n",
       "      <td>2787</td>\n",
       "      <td>3013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>19.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under-five deaths</th>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polio</th>\n",
       "      <td>6.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Expenditure</th>\n",
       "      <td>8.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.13</td>\n",
       "      <td>8.52</td>\n",
       "      <td>7.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diphtheria</th>\n",
       "      <td>65.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GDP</th>\n",
       "      <td>584.25921</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>669.959</td>\n",
       "      <td>63.537231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>33736494.0</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>2978599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <td>17.2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <td>17.3</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income_Composition_Resources</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schooling</th>\n",
       "      <td>10.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0            1            2  \\\n",
       "Country                       Afghanistan  Afghanistan  Afghanistan   \n",
       "Year                                 2015         2014         2013   \n",
       "Status                         Developing   Developing   Developing   \n",
       "Life_Expectancy                      65.0         59.9         59.9   \n",
       "Adult Mortality                     263.0        271.0        268.0   \n",
       "infant deaths                          62           64           66   \n",
       "Alcohol                              0.01         0.01         0.01   \n",
       "Percentage_Expenditure          71.279624    73.523582    73.219243   \n",
       "Hepatitis B                          65.0         62.0         64.0   \n",
       "Measles                              1154          492          430   \n",
       "BMI                                  19.1         18.6         18.1   \n",
       "under-five deaths                      83           86           89   \n",
       "Polio                                 6.0         58.0         62.0   \n",
       "Total_Expenditure                    8.16         8.18         8.13   \n",
       "Diphtheria                           65.0         62.0         64.0   \n",
       "HIV/AIDS                              0.1          0.1          0.1   \n",
       "GDP                             584.25921   612.696514   631.744976   \n",
       "Population                     33736494.0     327582.0   31731688.0   \n",
       "thinness  1-19 years                 17.2         17.5         17.7   \n",
       "thinness 5-9 years                   17.3         17.5         17.7   \n",
       "Income_Composition_Resources        0.479        0.476         0.47   \n",
       "Schooling                            10.1         10.0          9.9   \n",
       "\n",
       "                                        3            4  \n",
       "Country                       Afghanistan  Afghanistan  \n",
       "Year                                 2012         2011  \n",
       "Status                         Developing   Developing  \n",
       "Life_Expectancy                      59.5         59.2  \n",
       "Adult Mortality                     272.0        275.0  \n",
       "infant deaths                          69           71  \n",
       "Alcohol                              0.01         0.01  \n",
       "Percentage_Expenditure          78.184215     7.097109  \n",
       "Hepatitis B                          67.0         68.0  \n",
       "Measles                              2787         3013  \n",
       "BMI                                  17.6         17.2  \n",
       "under-five deaths                      93           97  \n",
       "Polio                                67.0         68.0  \n",
       "Total_Expenditure                    8.52         7.87  \n",
       "Diphtheria                           67.0         68.0  \n",
       "HIV/AIDS                              0.1          0.1  \n",
       "GDP                               669.959    63.537231  \n",
       "Population                      3696958.0    2978599.0  \n",
       "thinness  1-19 years                 17.9         18.2  \n",
       "thinness 5-9 years                   18.0         18.2  \n",
       "Income_Composition_Resources        0.463        0.454  \n",
       "Schooling                             9.8          9.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrangled_WHO_data = pd.read_csv(r'C:\\Users\\moder\\Documents\\Springboard\\PROJECTS ASSIGNMENTS files and instructions\\Capstones\\Capstone 2\\wrangled_WHO_data.csv')\n",
    "\n",
    "wrangled_WHO_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d3c5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2938 entries, 0 to 2937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Country                       2938 non-null   object \n",
      " 1   Year                          2938 non-null   int64  \n",
      " 2   Status                        2938 non-null   object \n",
      " 3   Life_Expectancy               2938 non-null   float64\n",
      " 4   Adult Mortality               2938 non-null   float64\n",
      " 5   infant deaths                 2938 non-null   int64  \n",
      " 6   Alcohol                       2938 non-null   float64\n",
      " 7   Percentage_Expenditure        2938 non-null   float64\n",
      " 8   Hepatitis B                   2938 non-null   float64\n",
      " 9   Measles                       2938 non-null   int64  \n",
      " 10  BMI                           2938 non-null   float64\n",
      " 11  under-five deaths             2938 non-null   int64  \n",
      " 12  Polio                         2938 non-null   float64\n",
      " 13  Total_Expenditure             2938 non-null   float64\n",
      " 14  Diphtheria                    2938 non-null   float64\n",
      " 15  HIV/AIDS                      2938 non-null   float64\n",
      " 16  GDP                           2938 non-null   float64\n",
      " 17  Population                    2938 non-null   float64\n",
      " 18  thinness  1-19 years          2938 non-null   float64\n",
      " 19  thinness 5-9 years            2938 non-null   float64\n",
      " 20  Income_Composition_Resources  2938 non-null   float64\n",
      " 21  Schooling                     2938 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(2)\n",
      "memory usage: 505.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#reminder - data types\n",
    "wrangled_WHO_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9a5944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2938 entries, 0 to 2937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Country                       2938 non-null   object \n",
      " 1   Year                          2938 non-null   int64  \n",
      " 2   Status                        2938 non-null   object \n",
      " 3   Life_Expectancy               2938 non-null   float64\n",
      " 4   Adult Mortality               2938 non-null   float64\n",
      " 5   infant deaths                 2938 non-null   int64  \n",
      " 6   Alcohol                       2938 non-null   float64\n",
      " 7   Percentage_Expenditure        2938 non-null   float64\n",
      " 8   Hepatitis B                   2938 non-null   float64\n",
      " 9   Measles                       2938 non-null   int64  \n",
      " 10  BMI                           2938 non-null   float64\n",
      " 11  under-five deaths             2938 non-null   int64  \n",
      " 12  Polio                         2938 non-null   float64\n",
      " 13  Total_Expenditure             2938 non-null   float64\n",
      " 14  Diphtheria                    2938 non-null   float64\n",
      " 15  HIV/AIDS                      2938 non-null   float64\n",
      " 16  GDP                           2938 non-null   float64\n",
      " 17  Population                    2938 non-null   float64\n",
      " 18  thinness  1-19 years          2938 non-null   float64\n",
      " 19  thinness 5-9 years            2938 non-null   float64\n",
      " 20  Income_Composition_Resources  2938 non-null   float64\n",
      " 21  Schooling                     2938 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(2)\n",
      "memory usage: 505.1+ KB\n"
     ]
    }
   ],
   "source": [
    "wrangled_WHO_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db537c0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b31d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  <class 'pandas.core.frame.DataFrame'> (2938, 3)\n"
     ]
    }
   ],
   "source": [
    "#I'm not going to use STATUS bc it's informed by all the other features, \n",
    "#plus I've noticed there is some issue with some countries not being designated correctly.\n",
    "\n",
    "X = wrangled_WHO_data[['Schooling','Income_Composition_Resources','Percentage_Expenditure']]\n",
    "print(\"X: \", type(X), X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae033a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Income_Composition_Resources</th>\n",
       "      <th>Percentage_Expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0.479</td>\n",
       "      <td>71.279624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>73.523582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>73.219243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.463</td>\n",
       "      <td>78.184215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.5</td>\n",
       "      <td>0.454</td>\n",
       "      <td>7.097109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.407</td>\n",
       "      <td>8.717409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>9.5</td>\n",
       "      <td>0.418</td>\n",
       "      <td>8.717409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>8.717409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.427</td>\n",
       "      <td>8.717409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>9.8</td>\n",
       "      <td>0.434</td>\n",
       "      <td>8.717409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2938 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Schooling  Income_Composition_Resources  Percentage_Expenditure\n",
       "0          10.1                         0.479               71.279624\n",
       "1          10.0                         0.476               73.523582\n",
       "2           9.9                         0.470               73.219243\n",
       "3           9.8                         0.463               78.184215\n",
       "4           9.5                         0.454                7.097109\n",
       "...         ...                           ...                     ...\n",
       "2933        9.2                         0.407                8.717409\n",
       "2934        9.5                         0.418                8.717409\n",
       "2935       10.0                         0.427                8.717409\n",
       "2936        9.8                         0.427                8.717409\n",
       "2937        9.8                         0.434                8.717409\n",
       "\n",
       "[2938 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50f244b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  <class 'pandas.core.series.Series'> (2938,)\n"
     ]
    }
   ],
   "source": [
    "y = wrangled_WHO_data['Life_Expectancy']\n",
    "print(\"y: \", type(y), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db9edf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Schooling', 'Income_Composition_Resources', 'Percentage_Expenditure']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b674ce00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       65.0\n",
       "1       59.9\n",
       "2       59.9\n",
       "3       59.5\n",
       "4       59.2\n",
       "        ... \n",
       "2933    44.3\n",
       "2934    44.5\n",
       "2935    44.8\n",
       "2936    45.3\n",
       "2937    46.0\n",
       "Name: Life_Expectancy, Length: 2938, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c68a769",
   "metadata": {},
   "source": [
    "# Split into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d5a6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training split has  2203  rows\n",
      " and the corresponding labels have an equal number of values. (2203)\n",
      "Test split has  735  rows\n",
      " and the corresponding labels have an equal number of values. (735)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47)\n",
    "print('Training split has ', X_train.shape[0], ' rows\\n',\n",
    "      'and the corresponding labels have an equal number of values.', \n",
    "      '(' + str(len(y_train))+ ')')\n",
    "print('Test split has ', X_test.shape[0], ' rows\\n',\n",
    "      'and the corresponding labels have an equal number of values.', \n",
    "      '(' + str(len(y_test)) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd1c98",
   "metadata": {},
   "source": [
    "# Recalling the guided capstone, it had us consider the MEAN - how good the mean is as a predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf1918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69.16806627]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the dummy regressor on the training data\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf325af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.16806627, 69.16806627, 69.16806627, 69.16806627, 69.16806627])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out some metrics - again referring back to guided capstone\n",
    "\n",
    "#r^2\n",
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc8037b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the R^2 - amount of variance\n",
    "def r_squared(y, ypred):\n",
    "    \"\"\"R-squared score.\n",
    "    \n",
    "    Calculate the R-squared, or coefficient of determination, of the input.\n",
    "    \n",
    "    Arguments:\n",
    "    y -- the observed values\n",
    "    ypred -- the predicted values\n",
    "    \"\"\"\n",
    "      \n",
    "    ybar = np.sum(y) / len(y) #yes, we could use np.mean(y)\n",
    "    sum_sq_tot = np.sum((y - ybar)**2) #total sum of squares error\n",
    "    sum_sq_res = np.sum((y - ypred)**2) #residual sum of squares error\n",
    "    R2 = 1.0 - sum_sq_res / sum_sq_tot\n",
    "    return R2\n",
    "\n",
    "r_squared(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3e2de",
   "metadata": {},
   "source": [
    "If you use the average value as your prediction, you get an R^2 of zero on the training set. What if you use this \"model\" to predict unseen values from the test set? Remember, of course, that your \"model\" is trained on the training set; you still use the training set mean as your prediction.\n",
    "\n",
    "Make your predictions by creating an array of length the size of the test set with the single value of the (training) mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93809a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.1680662732637"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the mean of `y_train`\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aebf19d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00038692692903219417"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r_squared(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1fadd91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.00038692692903219417)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use sklearn to compare\n",
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484d95e",
   "metadata": {},
   "source": [
    "OK this fits the data really poorly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c230396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.789523406059784, 7.775434364394878)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8bc96",
   "metadata": {},
   "source": [
    "SO this is saying that this essentially says, on average, we'd be off by around 8 (eight) years (of life expectancy) if we guessed based on an average of known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f80af760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.39889058662011, 90.51160014803055)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "506d2da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE:  9.507833117310174\n",
      "Test MSE:  9.513758465928728\n"
     ]
    }
   ],
   "source": [
    "print('Train MSE: ',np.sqrt(mean_squared_error(y_train, y_tr_pred)))\n",
    "print('Test MSE: ',np.sqrt(mean_squared_error(y_test, y_te_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa39213",
   "metadata": {},
   "source": [
    "Error on both train and test about 9.5 (life expectancy years)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a8088",
   "metadata": {},
   "source": [
    "# Standardize the magnitude of numeric features using a scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "183b6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# transform data\n",
    "#Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "#then use it's `transform()` method to apply the scaling to both the train and test split\n",
    "scaler.fit(X_train)\n",
    "X_tr_scaled = scaler.transform(X_train)\n",
    "X_te_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c381ae",
   "metadata": {},
   "source": [
    "# Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe7b7c",
   "metadata": {},
   "source": [
    "Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7fcd0c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e70e9b",
   "metadata": {},
   "source": [
    "Make predictions using the model on both train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4479b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e461f1",
   "metadata": {},
   "source": [
    "Assess model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22dcb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5385353447609016, 0.5473150595929861)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92816b",
   "metadata": {},
   "source": [
    "A simple linear regression model explains only about 50% of the variance on the train set and basically the same on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf569216",
   "metadata": {},
   "source": [
    "Calculate the mean absolute error scores using `sklearn`'s `mean_absolute_error` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f92a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.537319239862061, 4.500303323962902)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we did above for R^2\n",
    "# MAE - train, test\n",
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c1d9a",
   "metadata": {},
   "source": [
    "Using this model, then, on average you'd expect to estimate life expectancy within 4 or so years of the actual number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b49b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.71589287855163, 40.9573908017106)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And also do the same using `sklearn`'s `mean_squared_error`\n",
    "# MSE - train, test\n",
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "median_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb73096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE:  6.458784164109498\n",
      "Test MSE:  6.39979615313727\n"
     ]
    }
   ],
   "source": [
    "print('Train MSE: ',np.sqrt(mean_squared_error(y_train, y_tr_pred)))\n",
    "print('Test MSE: ',np.sqrt(mean_squared_error(y_test, y_te_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607f4b4",
   "metadata": {},
   "source": [
    "# Linear Regression: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3df4f0e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.5385353447609016\n",
      "\n",
      "Test score: 0.5473150595929861\n",
      "\n",
      "Overall model accuracy: 0.5473150595929861\n",
      "\n",
      "Mean Squared Error: 6.39979615313727\n"
     ]
    }
   ],
   "source": [
    "# score the model on the train set\n",
    "print('Train score: {}\\n'.format(lm.score(X_tr_scaled,y_train)))\n",
    "# score the model on the test set\n",
    "print('Test score: {}\\n'.format(lm.score(X_te_scaled,y_test)))\n",
    "# calculate the overall accuracy of the model\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,y_te_pred)))\n",
    "# compute the mean squared error of the model\n",
    "print('Mean Squared Error: {}'.format(np.sqrt(mean_squared_error(y_test,y_te_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb9c78",
   "metadata": {},
   "source": [
    "No overfitting here. But the MSE is high, the accuracy could be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92fd47aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model accuracy for comparison \n",
    "lraccuracy = r2_score(y_test,y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ade28d",
   "metadata": {},
   "source": [
    "# Model 2: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42959d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffe60c",
   "metadata": {},
   "source": [
    "Store rmse values for different k. RMSE measures the average difference between values predicted by a model and the actual values. It provides an estimation of how well the model is able to predict the target value (accuracy). A value of 0 would indicate a perfect fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eac59489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k= 1 is: 5.2013479414631805\n",
      "RMSE value for k= 2 is: 4.711426441710223\n",
      "RMSE value for k= 3 is: 4.6510138769030105\n",
      "RMSE value for k= 4 is: 4.681886525437672\n",
      "RMSE value for k= 5 is: 4.746261486184479\n",
      "RMSE value for k= 6 is: 4.769714310435647\n",
      "RMSE value for k= 7 is: 4.737246511636152\n",
      "RMSE value for k= 8 is: 4.782153164886291\n",
      "RMSE value for k= 9 is: 4.844528866621745\n",
      "RMSE value for k= 10 is: 4.844772408883368\n",
      "RMSE value for k= 11 is: 4.862030196762176\n",
      "RMSE value for k= 12 is: 4.862295753773678\n",
      "RMSE value for k= 13 is: 4.876721198983847\n",
      "RMSE value for k= 14 is: 4.881928251066693\n",
      "RMSE value for k= 15 is: 4.8872288039039296\n",
      "RMSE value for k= 16 is: 4.873857269205879\n",
      "RMSE value for k= 17 is: 4.885973395734088\n",
      "RMSE value for k= 18 is: 4.87057094017516\n",
      "RMSE value for k= 19 is: 4.8496291358214\n",
      "RMSE value for k= 20 is: 4.848108331737082\n"
     ]
    }
   ],
   "source": [
    "rmse_val = [] \n",
    "\n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "    \n",
    "    model.fit(X_tr_scaled, y_train) #fit model\n",
    "    pred = model.predict(X_te_scaled) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print(\"RMSE value for k=\", K, \"is:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6069d59d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve = pd.DataFrame(rmse_val)\n",
    "curve.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4dd6d2",
   "metadata": {},
   "source": [
    "I'm going to go with a K of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f05c7d",
   "metadata": {},
   "source": [
    "Instantiate and fit the model using the training data and training targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfa8e9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# instantiate the model and set the number of neighbors to consider to 3\n",
    "model2 = neighbors.KNeighborsRegressor(n_neighbors = 3)\n",
    "\n",
    "model2.fit(X_tr_scaled, y_train)\n",
    "\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a760bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78.        , 81.4       , 67.36666667, 52.7       , 63.2       ,\n",
       "       48.96666667, 78.23333333, 63.26666667, 78.06666667, 74.66666667,\n",
       "       79.8       , 61.53333333, 72.36666667, 67.13333333, 67.46666667,\n",
       "       79.43333333, 74.36666667, 81.4       , 63.4       , 75.03333333,\n",
       "       48.8       , 53.26666667, 59.1       , 72.33333333, 68.2       ,\n",
       "       74.23333333, 74.4       , 81.6       , 48.03333333, 65.16666667,\n",
       "       54.13333333, 74.03333333, 81.8       , 54.86666667, 62.16666667,\n",
       "       73.86666667, 75.46666667, 75.5       , 73.26666667, 73.26666667,\n",
       "       60.9       , 75.93333333, 68.5       , 49.23333333, 55.73333333,\n",
       "       55.63333333, 73.7       , 72.63333333, 72.86666667, 62.9       ,\n",
       "       75.66666667, 65.16666667, 76.86666667, 75.4       , 71.53333333,\n",
       "       77.4       , 62.33333333, 79.1       , 59.03333333, 72.6       ,\n",
       "       76.63333333, 66.5       , 75.73333333, 51.2       , 73.63333333,\n",
       "       73.86666667, 68.4       , 72.        , 76.4       , 65.66666667,\n",
       "       72.9       , 73.93333333, 68.3       , 73.26666667, 70.56666667,\n",
       "       62.13333333, 71.33333333, 63.26666667, 56.76666667, 74.06666667,\n",
       "       77.06666667, 74.23333333, 67.26666667, 64.6       , 51.        ,\n",
       "       72.96666667, 74.4       , 57.86666667, 74.13333333, 77.46666667,\n",
       "       75.13333333, 54.96666667, 80.4       , 74.5       , 70.4       ,\n",
       "       74.26666667, 71.6       , 73.63333333, 66.1       , 65.46666667,\n",
       "       65.26666667, 76.46666667, 75.5       , 76.8       , 59.73333333,\n",
       "       75.93333333, 81.6       , 67.06666667, 76.63333333, 74.56666667,\n",
       "       71.36666667, 77.13333333, 64.83333333, 81.76666667, 57.43333333,\n",
       "       60.9       , 62.9       , 66.2       , 51.33333333, 73.4       ,\n",
       "       76.76666667, 74.16666667, 60.33333333, 58.96666667, 79.43333333,\n",
       "       76.36666667, 72.56666667, 83.        , 46.33333333, 67.83333333,\n",
       "       50.53333333, 74.43333333, 57.6       , 75.53333333, 64.06666667,\n",
       "       67.53333333, 74.93333333, 50.8       , 73.83333333, 54.16666667,\n",
       "       81.43333333, 54.36666667, 53.3       , 74.9       , 70.8       ,\n",
       "       80.33333333, 58.2       , 68.33333333, 73.13333333, 71.16666667,\n",
       "       78.5       , 60.86666667, 72.63333333, 75.23333333, 75.1       ,\n",
       "       74.9       , 71.8       , 73.5       , 72.36666667, 75.8       ,\n",
       "       71.76666667, 53.3       , 57.03333333, 67.03333333, 44.96666667,\n",
       "       81.66666667, 73.66666667, 55.26666667, 82.46666667, 71.53333333,\n",
       "       74.16666667, 74.26666667, 50.53333333, 78.36666667, 59.4       ,\n",
       "       74.1       , 75.7       , 74.56666667, 78.2       , 61.73333333,\n",
       "       58.76666667, 59.3       , 82.66666667, 67.66666667, 72.8       ,\n",
       "       74.7       , 63.03333333, 80.9       , 78.63333333, 78.33333333,\n",
       "       63.56666667, 72.5       , 73.86666667, 82.13333333, 73.26666667,\n",
       "       70.76666667, 65.83333333, 57.13333333, 60.06666667, 68.73333333,\n",
       "       66.2       , 72.03333333, 61.66666667, 67.46666667, 74.73333333,\n",
       "       83.13333333, 79.7       , 78.7       , 78.26666667, 56.76666667,\n",
       "       74.86666667, 73.56666667, 57.3       , 80.        , 62.2       ,\n",
       "       72.56666667, 71.13333333, 75.8       , 80.33333333, 78.73333333,\n",
       "       76.23333333, 54.3       , 83.56666667, 73.9       , 71.        ,\n",
       "       57.8       , 81.5       , 64.86666667, 73.66666667, 50.23333333,\n",
       "       59.96666667, 71.53333333, 82.56666667, 65.6       , 83.7       ,\n",
       "       62.4       , 56.26666667, 73.56666667, 71.13333333, 66.1       ,\n",
       "       74.5       , 64.03333333, 58.66666667, 75.86666667, 75.43333333,\n",
       "       65.5       , 73.36666667, 73.26666667, 73.86666667, 76.16666667,\n",
       "       61.96666667, 63.23333333, 74.6       , 78.4       , 77.9       ,\n",
       "       77.9       , 57.66666667, 74.16666667, 74.7       , 51.16666667,\n",
       "       76.1       , 54.53333333, 81.3       , 80.3       , 82.23333333,\n",
       "       50.6       , 74.56666667, 62.8       , 61.46666667, 73.06666667,\n",
       "       76.5       , 80.33333333, 80.9       , 80.9       , 75.6       ,\n",
       "       72.43333333, 48.2       , 72.2       , 60.        , 74.16666667,\n",
       "       63.43333333, 72.3       , 61.43333333, 82.2       , 73.13333333,\n",
       "       72.83333333, 59.16666667, 81.66666667, 54.46666667, 54.53333333,\n",
       "       70.5       , 69.06666667, 80.26666667, 81.        , 58.66666667,\n",
       "       59.03333333, 53.63333333, 78.        , 75.2       , 78.46666667,\n",
       "       73.3       , 68.2       , 51.73333333, 73.5       , 72.23333333,\n",
       "       75.6       , 63.16666667, 76.1       , 63.13333333, 65.73333333,\n",
       "       64.8       , 65.16666667, 80.6       , 70.96666667, 72.53333333,\n",
       "       76.        , 73.16666667, 83.7       , 72.6       , 81.4       ,\n",
       "       69.7       , 74.23333333, 71.6       , 82.06666667, 65.        ,\n",
       "       82.06666667, 82.        , 74.2       , 63.16666667, 75.06666667,\n",
       "       81.1       , 74.7       , 84.66666667, 67.3       , 52.16666667,\n",
       "       81.46666667, 83.7       , 73.23333333, 74.16666667, 70.43333333,\n",
       "       79.96666667, 71.76666667, 72.6       , 59.36666667, 73.66666667,\n",
       "       69.93333333, 72.63333333, 73.4       , 69.93333333, 80.66666667,\n",
       "       75.53333333, 49.76666667, 73.66666667, 65.36666667, 55.73333333,\n",
       "       75.33333333, 52.4       , 71.93333333, 74.13333333, 71.7       ,\n",
       "       68.8       , 70.        , 63.66666667, 73.06666667, 71.2       ,\n",
       "       76.1       , 64.5       , 69.2       , 68.1       , 73.73333333,\n",
       "       79.36666667, 75.8       , 69.63333333, 72.86666667, 72.3       ,\n",
       "       56.33333333, 66.        , 51.        , 84.93333333, 71.43333333,\n",
       "       85.5       , 63.06666667, 77.06666667, 73.13333333, 60.53333333,\n",
       "       78.5       , 75.76666667, 72.3       , 44.86666667, 65.7       ,\n",
       "       65.13333333, 82.13333333, 74.4       , 78.06666667, 83.4       ,\n",
       "       73.26666667, 66.53333333, 73.06666667, 72.43333333, 79.13333333,\n",
       "       69.73333333, 71.06666667, 76.76666667, 72.96666667, 62.36666667,\n",
       "       77.56666667, 57.16666667, 69.61666667, 67.43333333, 72.36666667,\n",
       "       71.86666667, 82.16666667, 74.36666667, 67.76666667, 73.16666667,\n",
       "       64.66666667, 79.4       , 65.73333333, 73.76666667, 76.43333333,\n",
       "       55.36666667, 74.26666667, 72.        , 51.03333333, 65.86666667,\n",
       "       65.26666667, 73.16666667, 80.4       , 61.23333333, 63.93333333,\n",
       "       82.06666667, 63.53333333, 71.2       , 58.16666667, 78.8       ,\n",
       "       59.        , 72.43333333, 72.3       , 54.4       , 63.16666667,\n",
       "       78.23333333, 74.        , 69.66666667, 58.93333333, 78.8       ,\n",
       "       78.8       , 54.86666667, 81.66666667, 72.9       , 70.66666667,\n",
       "       73.8       , 54.53333333, 75.        , 75.43333333, 54.46666667,\n",
       "       65.86666667, 70.96666667, 72.26666667, 62.33333333, 56.76666667,\n",
       "       48.46666667, 76.9       , 51.26666667, 75.46666667, 78.86666667,\n",
       "       72.43333333, 48.3       , 81.26666667, 79.36666667, 64.33333333,\n",
       "       70.96666667, 60.33333333, 74.03333333, 62.73333333, 73.66666667,\n",
       "       59.3       , 70.5       , 67.7       , 63.23333333, 59.7       ,\n",
       "       80.33333333, 74.86666667, 76.3       , 70.7       , 52.3       ,\n",
       "       74.2       , 60.63333333, 81.26666667, 65.1       , 71.3       ,\n",
       "       74.33333333, 78.        , 77.        , 66.13333333, 75.16666667,\n",
       "       66.2       , 68.4       , 62.8       , 76.8       , 66.46666667,\n",
       "       82.1       , 57.93333333, 64.06666667, 77.63333333, 74.9       ,\n",
       "       56.4       , 51.83333333, 74.96666667, 75.33333333, 70.9       ,\n",
       "       56.73333333, 73.26666667, 57.66666667, 72.43333333, 57.9       ,\n",
       "       74.23333333, 74.2       , 57.        , 67.36666667, 73.46666667,\n",
       "       67.86666667, 68.33333333, 53.3       , 75.8       , 74.36666667,\n",
       "       64.23333333, 79.36666667, 70.86666667, 61.33333333, 61.66666667,\n",
       "       70.43333333, 63.4       , 70.86666667, 63.23333333, 80.86666667,\n",
       "       74.76666667, 54.66666667, 60.63333333, 70.73333333, 74.26666667,\n",
       "       73.73333333, 67.6       , 53.8       , 75.8       , 59.2       ,\n",
       "       79.83333333, 74.1       , 69.13333333, 72.53333333, 74.8       ,\n",
       "       69.83333333, 73.83333333, 84.83333333, 73.7       , 79.16666667,\n",
       "       47.63333333, 75.83333333, 82.43333333, 71.93333333, 59.66666667,\n",
       "       72.8       , 55.26666667, 75.33333333, 75.2       , 82.83333333,\n",
       "       59.16666667, 54.66666667, 61.23333333, 67.2       , 83.66666667,\n",
       "       72.33333333, 74.56666667, 78.2       , 75.46666667, 65.46666667,\n",
       "       72.56666667, 72.56666667, 74.43333333, 66.03333333, 71.8       ,\n",
       "       71.9       , 65.7       , 72.26666667, 74.06666667, 77.33333333,\n",
       "       81.53333333, 75.13333333, 72.53333333, 69.7       , 60.23333333,\n",
       "       71.6       , 59.8       , 79.56666667, 74.43333333, 73.96666667,\n",
       "       50.43333333, 67.43333333, 65.16666667, 82.        , 71.13333333,\n",
       "       81.06666667, 58.8       , 68.4       , 77.13333333, 72.8       ,\n",
       "       73.33333333, 73.76666667, 77.86666667, 75.43333333, 77.26666667,\n",
       "       61.23333333, 58.2       , 57.03333333, 79.5       , 75.5       ,\n",
       "       72.16666667, 76.06666667, 74.2       , 78.83333333, 70.16666667,\n",
       "       62.36666667, 56.43333333, 74.86666667, 58.7       , 70.43333333,\n",
       "       70.7       , 69.5       , 83.36666667, 72.3       , 76.23333333,\n",
       "       72.63333333, 77.73333333, 79.26666667, 70.5       , 68.96666667,\n",
       "       68.73333333, 76.16666667, 72.9       , 80.4       , 54.4       ,\n",
       "       71.93333333, 59.13333333, 80.46666667, 78.43333333, 73.03333333,\n",
       "       71.46666667, 53.3       , 57.3       , 69.13333333, 71.        ,\n",
       "       68.53333333, 70.        , 77.36666667, 78.6       , 66.03333333,\n",
       "       64.9       , 58.43333333, 58.46666667, 63.96666667, 59.7       ,\n",
       "       81.43333333, 63.63333333, 82.1       , 65.23333333, 65.33333333,\n",
       "       72.1       , 54.93333333, 62.73333333, 50.33333333, 73.2       ,\n",
       "       51.83333333, 74.2       , 63.16666667, 52.83333333, 71.8       ,\n",
       "       73.06666667, 71.08333333, 72.3       , 75.03333333, 72.73333333,\n",
       "       50.23333333, 77.6       , 78.8       , 70.63333333, 68.        ,\n",
       "       71.73333333, 68.06666667, 54.26666667, 80.93333333, 57.43333333,\n",
       "       79.96666667, 71.16666667, 71.03333333, 70.63333333, 71.73333333,\n",
       "       55.1       , 75.86666667, 71.23333333, 75.36666667, 55.56666667,\n",
       "       73.06666667, 49.3       , 85.46666667, 75.26666667, 74.8       ,\n",
       "       53.93333333, 79.7       , 48.1       , 78.        , 81.43333333,\n",
       "       65.7       , 75.63333333, 60.93333333, 60.16666667, 67.9       ,\n",
       "       70.76666667, 62.33333333, 54.96666667, 75.        , 80.73333333,\n",
       "       59.2       , 67.1       , 61.53333333, 75.73333333, 78.83333333,\n",
       "       79.66666667, 59.76666667, 72.66666667, 49.13333333, 73.4       ,\n",
       "       77.06666667, 81.56666667, 75.73333333, 72.9       , 83.5       ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23860e0",
   "metadata": {},
   "source": [
    "# KNN Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ba04f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8923908807832247\n",
      "\n",
      "Test score: 0.7609113083402785\n",
      "\n",
      "Overall model accuracy: 0.7402183946799865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score the model on the train set\n",
    "print('Train score: {}\\n'.format(model2.score(X_tr_scaled,y_train)))\n",
    "# score the model on the test set\n",
    "print('Test score: {}\\n'.format(model2.score(X_te_scaled,y_test)))\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92b495",
   "metadata": {},
   "source": [
    "OK so this is a bit overfitted. But accuracy/precision is at 74%! Let's try Decision Tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7a1a6",
   "metadata": {},
   "source": [
    "<One note: the more independent variables I feed into the model, it appears, the better scores/performance. With only 3 the performance here is slightly worse.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d2d4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model accuracy for comparison\n",
    "knnaccuracy = r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f09cbb",
   "metadata": {},
   "source": [
    "# Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d88dad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor() # initialize a DecisionTreeRegressor model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae00a82",
   "metadata": {},
   "source": [
    "Fit regression model, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2631d5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6229755467004949\n",
      "MAE:  3.7697278911564625\n",
      "MSE:  5.840538310387326\n"
     ]
    }
   ],
   "source": [
    "dtree.fit(X_train, y_train)\n",
    "yhat = dtree.predict(X_test)\n",
    "print(\"Score: \",r2_score(y_test, yhat))\n",
    "print(\"MAE: \",mean_absolute_error(y_test, yhat))\n",
    "print(\"MSE: \",np.sqrt(mean_squared_error(y_test, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1440f",
   "metadata": {},
   "source": [
    "The score is only about 61% (precision/accuracy). That could be higher. The MAE and MSE aren't so bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067ccf4",
   "metadata": {},
   "source": [
    "Comparing the Real Values with Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00f9f071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>76.0</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>85.0</td>\n",
       "      <td>77.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>73.0</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>62.1</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>53.8</td>\n",
       "      <td>53.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>76.3</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>69.8</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>74.9</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>78.6</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Real Values  Predicted Values\n",
       "1929         76.0              73.4\n",
       "2347         85.0              77.3\n",
       "1876         73.0              71.3\n",
       "2257         62.1              51.4\n",
       "846          53.8              53.2\n",
       "...           ...               ...\n",
       "2750         76.3              76.0\n",
       "2515         85.0              88.0\n",
       "708          69.8              79.3\n",
       "655          74.9              72.0\n",
       "1860         78.6              78.3\n",
       "\n",
       "[735 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':yhat})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61222d0",
   "metadata": {},
   "source": [
    "Try to improve accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c8228",
   "metadata": {},
   "source": [
    "# Tuning of the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e0e2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters\n",
    "params = {'max_features':['auto','sqrt','log2'],\n",
    "         'min_samples_split':[2,3,4,5,6,7,8,9],\n",
    "         'min_samples_leaf':[1,2,3,4,5,6,7,8,9],\n",
    "         'max_depth':[2,3,4,5,6,7]}                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85eead49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the grid search\n",
    "tree_search = GridSearchCV(dtree,params,cv=5,n_jobs=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b9c73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_search.fit(X_train,y_train)   # fit the model\n",
    "tree_pred = tree_search.predict(X_test)  # make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d4331c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter found:\n",
      "{'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
      "\n",
      "Train score: 0.8146391805761136\n",
      "\n",
      "Test score: 0.7384522285567381\n",
      "\n",
      "Overall model accuracy: 0.7384522285567381\n",
      "\n",
      "Mean Squared Error: 4.864560729249615\n"
     ]
    }
   ],
   "source": [
    "# print out the best parameters found and score the model\n",
    "print('Best parameter found:\\n{}\\n'.format(tree_search.best_params_))\n",
    "print('Train score: {}\\n'.format(tree_search.score(X_train,y_train)))\n",
    "print('Test score: {}\\n'.format(tree_search.score(X_test,y_test)))\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,tree_pred)))\n",
    "print('Mean Squared Error: {}'.format(np.sqrt(mean_squared_error(y_test,tree_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd3ed0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save model accuracy for comparison\n",
    "dtaccuracy = r2_score(y_test,tree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51c8bc",
   "metadata": {},
   "source": [
    "This isn't performing as well as KNN and is also overfitted. But GridSearchCV helped A LOT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb8273",
   "metadata": {},
   "source": [
    "# Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbc3465d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#RF doesn't need scaled data\n",
    "forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60513181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating the model on Training Data\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "prediction=forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc7c53ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9705397736059173\n",
      "\n",
      "Test score: 0.7848989356113409\n",
      "\n",
      "Overall model accuracy: 0.7848989356113409\n",
      "\n",
      "Mean Squared Error: 4.411531628568919\n"
     ]
    }
   ],
   "source": [
    "#scoring\n",
    "print('Train score: {}\\n'.format(forest.score(X_train,y_train)))\n",
    "print('Test score: {}\\n'.format(forest.score(X_test,y_test)))\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,prediction)))\n",
    "print('Mean Squared Error: {}'.format(np.sqrt(mean_squared_error(y_test,prediction))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c35458",
   "metadata": {},
   "source": [
    "This is way overfitted but the accuracy is pretty high!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12133bf",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8af4663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter found:\n",
      "{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 7}\n",
      "\n",
      "Train score: 0.8602501752632792\n",
      "\n",
      "Test score: 0.780651609188295\n",
      "\n",
      "Overall model accuracy: 0.780651609188295\n",
      "\n",
      "Mean Squared Error: 4.454873166666297\n"
     ]
    }
   ],
   "source": [
    "# we add the n_estimators parameter in our previous parameter dictionary\n",
    "params['n_estimators'] = [100,200,300,400,500]\n",
    "\n",
    "\n",
    "forest_search = RandomizedSearchCV(forest,params,cv=5,n_jobs=-1,     # initialize the search\n",
    "                                  n_iter=50)\n",
    "\n",
    "\n",
    "forest_search.fit(X_train,y_train)  # fit the model\n",
    "\n",
    "\n",
    "forest_pred = forest_search.predict(X_test)  # make prediction with the model\n",
    "\n",
    "\n",
    "# print out the best parameters and score the model\n",
    "print('Best parameter found:\\n{}\\n'.format(forest_search.best_params_))\n",
    "print('Train score: {}\\n'.format(forest_search.score(X_train,y_train)))\n",
    "print('Test score: {}\\n'.format(forest_search.score(X_test,y_test)))\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,forest_pred)))\n",
    "print('Mean Squared Error: {}'.format(np.sqrt(mean_squared_error(y_test,forest_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c775f1a",
   "metadata": {},
   "source": [
    "Interesting that this has reduced overfitting but didn't improve accuracy or MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c92f258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model accuracy for comparison\n",
    "rfaccuracy = r2_score(y_test,forest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e7e80",
   "metadata": {},
   "source": [
    "# Model 5: Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94f896",
   "metadata": {},
   "source": [
    "I'm just going to go ahead and apply the tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7da42ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter found:\n",
      "{'n_estimators': 400, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_depth': 6, 'learning_rate': 0.05}\n",
      "\n",
      "Train score: 0.9168403996965002\n",
      "\n",
      "Test score: 0.7860722051058229\n",
      "\n",
      "Overall model accuracy: 0.7860722051058229\n",
      "\n",
      "Mean Squared Error: 4.3994838201921525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train a GradientBoostingRegressor model\n",
    "\n",
    "gradient_model = GradientBoostingRegressor()  # instantiate the model\n",
    "\n",
    "# append a learning_rate parameter to the parameter dictionary\n",
    "params['learning_rate'] = [0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "gradient_search = RandomizedSearchCV(gradient_model,params,cv=5,n_jobs=-1,\n",
    "                                  n_iter=50)   # initialize the search\n",
    "\n",
    "gradient_search.fit(X_train,y_train)   # fit the model\n",
    "\n",
    "gradient_pred = gradient_search.predict(X_test)  # make predictions with the model\n",
    "\n",
    "# print out the best parameters and score the model\n",
    "print('Best parameter found:\\n{}\\n'.format(gradient_search.best_params_))\n",
    "print('Train score: {}\\n'.format(gradient_search.score(X_train,y_train)))\n",
    "print('Test score: {}\\n'.format(gradient_search.score(X_test,y_test)))\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test,gradient_pred)))\n",
    "print('Mean Squared Error: {}\\n'.format(np.sqrt(mean_squared_error(y_test,gradient_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d399d",
   "metadata": {},
   "source": [
    "This is very overfitted, unfortunately. But high accuracy and the error isn't too bad. This is performing about as well as the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c12e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model accuracy for comparison of models\n",
    "gbaccuracy = r2_score(y_test,gradient_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d728a8",
   "metadata": {},
   "source": [
    "# Compare scoring of all models under consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da230ac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression accuracy:  0.5473150595929861\n",
      "KNN accuracy:  0.7402183946799865\n",
      "Decision Tree accuracy:  0.7384522285567381\n",
      "Random Forest accuracy:  0.780651609188295\n",
      "Gradient Boosting accuracy:  0.7860722051058229\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression accuracy: \", lraccuracy)\n",
    "print(\"KNN accuracy: \", knnaccuracy)\n",
    "print(\"Decision Tree accuracy: \", dtaccuracy)\n",
    "print(\"Random Forest accuracy: \", rfaccuracy)\n",
    "print(\"Gradient Boosting accuracy: \", gbaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167cf61",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df054f",
   "metadata": {},
   "source": [
    "The best model here is Random Forest. It has essentially the same accuracy as Gradient Boosting, however, the GB model is much more overfitted. Considering overfitting: Decision Tree and Random Forest about the same as far as overfitting, but the RF has a higher accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
